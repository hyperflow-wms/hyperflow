#!/usr/bin/env node

var redisURL = process.env.REDIS_URL ? {url: process.env.REDIS_URL} : undefined

var docopt = require('docopt').docopt,
    spawn = require('child_process').spawn,
    fs = require('fs'),
    pathtool = require('path'),
    redis = require('redis'),
    rcl = redisURL ? redis.createClient(redisURL): redis.createClient(),
    wflib = require('../wflib').init(rcl),
    Engine = require('../engine2'),
    async = require('async'),
    dbId = 0,
    plugins = [],
    recoveryMode = false, recoveryData = { 'input': [], 'outputs': {} },
    wfDirFull; // logged in the persistence journal

var doc = "\
Usage:\n\
  hflow run <workflow_dir_or_file> [-s] [--with-server] [--log-provenance] [--provenance-output=<provenance_file>] [-p <plugin_module_name> ...]\n\
  hflow recover <persistence-log> [-p <plugin_module_name> ...]\n\
  hflow start-server [-p <plugin_module_name> ...]\n\
  hflow send <wf_id> ( <signal_file> | -d <signal_data> ) [-p <plugin_module_name> ...]\n\
  hflow -h | --help | --version";

var opts = docopt(doc);
var hfroot = pathtool.join(require('path').dirname(require.main.filename), "..");

if (opts['-p']) {
    opts['<plugin_module_name>'].forEach(load_plugin);
}

if (opts.run) {
  hflow_run();
} else if (opts.send) {
  hflow_send();
} else if (opts['start-server']) {
  hflow_start();
} else if (opts.recover) {
  hflow_recover();
}

function load_plugin(plugin_name) {
    try {
        var Plugin = require(plugin_name);
        plugins.push(new Plugin());
    } catch (err) {
        console.log("Plugin module:", plugin_name, "not found!");
        console.log(err);
        process.exit(1);
    }
}

function append_file(data, cb) {
    fs.appendFile(data["filename"], JSON.stringify(data["args"]) + "\n", function (err) {
        if (err) {
            console.log("Error appending to file! " + err);
        }
        cb();
    });
}

var queue = async.queue(append_file, 1);

function hflow_start() {
    var server = require('../server/hyperflow-server.js')(rcl, wflib);
    server.listen(process.env.PORT, function() { });
    console.log("HyperFlow server started, app factory URI: http://%s:%d/apps", server.address().address, server.address().port);
}

function hflow_run() {
  var wfpath = recoveryMode ? wfDirFull: opts['<workflow_dir_or_file>'], // if this is recovery, full wf dir path was already read from the journal, otherwise it will be resolved
      wfstats = fs.lstatSync(wfpath),
      wffile;

  if (opts['--with-server']) {
      hflow_start(); // start the HTTP server
  }

  if (wfstats.isDirectory()) {
    wffile = pathtool.join(wfpath, "workflow.json");
  } else if (wfstats.isFile()) {
    wffile = wfpath;
    wfpath = pathtool.dirname(wfpath);
  }

  wfDirFull = pathtool.resolve(wfpath);

  var runWf = function(wfId, wfName) {

    /*function makeId() {
        var id = [];
        var possible = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789";

        for( var i=0; i < 5; i++ )
            id[i] = possible.charAt(Math.floor(Math.random() * possible.length));

        return id.join("");
    }*/

    var config = {"emulate":"false", "workdir": wfDirFull};
    
    if (recoveryMode) {
        config.recoveryData = recoveryData;
        config.recovery = true;
    }

    //console.log(JSON.stringify(recoveryData, null, 2));
    //process.exit(1);

    var engine = new Engine(config, wflib, wfId, function(err) {
      // This represent custom plugin listening on event from available eventServer
      // engine.eventServer.on('trace.*', function(exec, args) {
      //   console.log('Event captured: ' + exec + ' ' + args + ' job done');
      // });

      plugins.forEach(function(plugin) {
          plugin.init(rcl, wflib, engine);
      });

      if (opts['--log-provenance']) {
          engine.logProvenance = true;
          var provenance_output = opts['--provenance-output'] || 'provenance_log.txt';
          if (!pathtool.isAbsolute(provenance_output)) {
              provenance_output = pathtool.join(process.cwd(), provenance_output);
          }
          engine.eventServer.on('prov', function() {
              queue.push( { "filename": provenance_output, "args": arguments}, function(err) {
                  if (err) {
                      console.log("queue errror! " + err);
                  }
              });
          });
      }

      // TODO: implement a plugin for different persistence backends
      // FIXME: generate unique persist-log file name
      var date = new Date().toISOString().replace(new RegExp('[T:.]', 'g'), '-').replace('Z', '');
      var logFileName = (wfName ? wfName: 'wf').concat('.' + date + ".log");
      console.log("Persistence log:", logFileName);
      var persistlog=pathtool.join(process.cwd(), logFileName);
      engine.eventServer.on('persist', function() {
          queue.push( { "filename": persistlog, "args": arguments }, function(err) {
              if (err) {
                  console.log("queue errror! " + err);
              }
          });
      });

      // we persist the full workflow directory path and execution options used to run the workflow
      engine.eventServer.emit('persist', ["info", wfDirFull, JSON.stringify(opts)]);

      engine.runInstance(function(err) {
        console.log("Wf id="+wfId);
        if (opts['-s']) {
          // Flag -s is present: send all input signals to the workflow -> start execution
          wflib.getWfIns(wfId, false, function(err, wfIns) {
            engine.wflib.getSignalInfo(wfId, wfIns, function(err, sigs) {
              engine.emitSignals(sigs);
            });
          });
        }
      });
    });
  };

  var createWf = function(cb) {
    rcl.select(dbId, function(err, rep) {
      //rcl.flushdb(function(err, rep) { // flushing db here deletes the global 'hfid' entry (created earlier)
        wflib.createInstanceFromFile(wffile, '', function(err, id, wfJson) {
          cb(err, id, wfJson.name);
        });
      //});
    });
  }

   var startWf = function() {
       createWf(function (err, wfId, wfName) {
           runWf(wfId, wfName);
       });
   };

   startWf();
}

function hflow_recover() {
    var recoveryFile = opts['<persistence-log>'];
    var persistLog = fs.readFileSync(recoveryFile, 'utf8').toString().trim().split('\n');
    persistLog.forEach(function(entry, index) {
            persistLog[index] = JSON.parse(entry)['1'];
    });

    persistLog.forEach(function(entry) {
        if (entry[0] == 'info') { // full wf dir path and command line options
            wfDirFull = entry[1]; 
            opts = JSON.parse(entry[2]); // we recover command line options used to run the workflow
        } else if (entry[0] == 'input') {
            var sigData = entry[2];
            delete sigData.sigIdx;
            recoveryData['input'].push(sigData);
        } else if (entry[0] == 'fired') {
            var procId = entry[2], 
            firingId = entry[3], 
            outs = entry[4],
            key = procId + '_' + firingId;
            recoveryData.outputs[key] = outs;
        }
    });

    recoveryMode = true;

    hflow_run();
}

function hflow_send() {
  console.log("send signal to a workflow: not implemented");
}

function spawn_proc(exec, args) {
  var proc = spawn(exec, args);

  proc.stdout.on('data', function(data) {
    console.log(data.toString().trimRight());
  });

  proc.stderr.on('data', function(data) {
    console.log(data.toString().trimRight());
  });
}
